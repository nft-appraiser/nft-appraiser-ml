{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b83eaf3b-a15b-42fd-99da-dc9e6950f7bd",
   "metadata": {},
   "source": [
    "# 価格予測モデルのBaseline  \n",
    "- CNNを用いたモデルを作成する．  \n",
    "- 価格予測とクラス分類でタスクが大きく異なるので，imagenetで学習したモデルを用いないものを最初に作成する．  \n",
    "- サイトに載せられる画像を教師データとしており，画像が大きく回転したりなどは不要と考えられるためそのような前処理は行わない．  \n",
    "- 損失関数にはmaeもしくはrmseを用いる．  \n",
    "\n",
    "## モデルの構築  \n",
    "- EfficientNetB0（未学習）を用いて特徴量を抽出．  \n",
    "- num_sales, コレクション名のone-hotベクトルを抽出した特徴量に結合．  \n",
    "- 全結合層を重ねて出力．  \n",
    "- ImageNetを用いて事前学習したものとしていないもので比較する．  \n",
    "- 目的変数をそのまま予測するとスケールが大きすぎるので，先に対数変換して評価関数にRMSE, MAEなどを用いるほうが良いかも．  \n",
    "- **このノートブックでやっているのは事前学習有り．**  \n",
    "\n",
    "## 評価関数  \n",
    "- RMSLEを用いる．  \n",
    "$$RMSLE = \\sqrt{\\frac{1}{n}\\sum_{i=1}^n (\\log{(y_i+1)} - \\log{(\\hat{y_i} +1)})^2}$$\n",
    "\n",
    "- 追加でMAPEを用いてみる．  \n",
    "$$MAPE = \\frac{100}{n} \\sum_{i=1}^n |\\frac{\\hat{y}_i - y_i}{y_i}|$$\n",
    "\n",
    "タスクAに関してはデータ不足の可能性が考えられるため，特徴量抽出とともにデータを追加で収集する．  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcd6e453-d7a2-447a-94c2-e3e41e7c841e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import List, Optional, Tuple, Dict\n",
    "import math\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.models as models\n",
    "import tensorflow.keras.losses as losses\n",
    "import tensorflow.keras.optimizers as optim\n",
    "import tensorflow.keras.activations as activations\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "import tensorflow.keras.callbacks as callbacks\n",
    "from tensorflow.keras.applications import EfficientNetB0 as efn\n",
    "import cloudpickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1adc001b-4234-4ec3-9b9d-b23a47cca243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: (4136, 18)\n",
      "data shape: (37296, 23)\n"
     ]
    }
   ],
   "source": [
    "A_IMGPATH = \"data/taskA/img\"\n",
    "A_DFPATH = \"data/taskA/table\"\n",
    "B_IMGPATH = \"data/taskB/img\"\n",
    "B_DFPATH = \"data/taskB/table\"\n",
    "asset_df_A = pd.read_csv(os.path.join(A_DFPATH, \"asset_data.csv\"))\n",
    "asset_df_B = pd.read_csv(os.path.join(B_DFPATH, \"asset_data.csv\"))\n",
    "\n",
    "asset_df_A = pd.concat((asset_df_A, pd.get_dummies(asset_df_A['asset_contract.name'])), axis=1)\n",
    "asset_df_B[asset_df_A.columns.values[8:]] = 0\n",
    "asset_df_B = asset_df_B.rename(columns={\"asset.num_sales\": \"num_sales\"})\n",
    "asset_df_A = asset_df_A.rename(columns={\"last_sale.total_price\": \"current_price\"})\n",
    "asset_df_A['current_price'] = asset_df_A['current_price'].astype(float)\n",
    "\n",
    "asset_df_A[\"full_path\"] =\\\n",
    "    asset_df_A[\"image_id\"].apply(lambda x: A_IMGPATH + \"/\" + x)\n",
    "asset_df_B[\"full_path\"] =\\\n",
    "    asset_df_B[\"image_id\"].apply(lambda x: B_IMGPATH + \"/\" + x)\n",
    "asset_df_A['current_price'] = asset_df_A['current_price'] * 1e-18\n",
    "asset_df_B['current_price'] = asset_df_B['current_price'] * 1e-18\n",
    "asset_df_A = asset_df_A.query('current_price > 0')\n",
    "asset_df_B = asset_df_B.query('current_price > 0')\n",
    "asset_df_A['current_price'] = asset_df_A['current_price'].apply(lambda x: np.log1p(x))\n",
    "asset_df_B['current_price'] = asset_df_B['current_price'].apply(lambda x: np.log1p(x))\n",
    "\n",
    "print(f\"data shape: {asset_df_A.shape}\")\n",
    "print(f\"data shape: {asset_df_B.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd9128f-90a3-4a76-a850-c81273b9967d",
   "metadata": {},
   "source": [
    "## Helper Functions  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2126e4f-9af4-4b15-9bde-dc1a5f8a1124",
   "metadata": {},
   "source": [
    "### DataLoader  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deb23666-1673-4db8-85da-9f8aa0fcbd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullPathDataLoader(Sequence):\n",
    "    \"\"\"\n",
    "    Data loader that load images, meta data and targets.\n",
    "    This class is inherited Sequence class of Keras.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path_list: np.ndarray, meta_data: np.ndarray,\n",
    "                 target: Optional[np.ndarray], batch_size: int, width: int = 256,\n",
    "                 height: int = 256, resize: bool = True,\n",
    "                 shuffle: bool = True, is_train: bool = True):\n",
    "        \"\"\"\n",
    "        Constructor. This method determines class variables.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        path_list : np.ndarray[str]\n",
    "            The array of absolute paths of images.\n",
    "        meta_data : np.ndarray[int]\n",
    "            One-hot vector of collections.\n",
    "        target : np.ndarray\n",
    "            Array of target variavles.\n",
    "        batch_size : int\n",
    "            Batch size used when model training.\n",
    "        width : int\n",
    "            Width of resized image.\n",
    "        height : int\n",
    "            Height of resize image.\n",
    "        resize : bool\n",
    "            Flag determine whether to resize.\n",
    "        shuffle : bool\n",
    "            Flag determine whether to shuffle on epoch end.\n",
    "        is_train : bool\n",
    "            Determine whether this data loader will be used training model.\n",
    "            if you won't this data loader, you have set 'is_train'=False.\n",
    "        \"\"\"\n",
    "        self.path_list = path_list\n",
    "        self.meta_data = meta_data\n",
    "        self.batch_size = batch_size\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.resize = resize\n",
    "        self.shuffle = shuffle\n",
    "        self.is_train = is_train\n",
    "        self.length = math.ceil(len(self.path_list) / self.batch_size)\n",
    "\n",
    "        if self.is_train:\n",
    "            self.target = target\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns\n",
    "        -------\n",
    "        self.length : data length\n",
    "        \"\"\"\n",
    "        return self.length\n",
    "\n",
    "    def get_img(self, path_list: np.ndarray):\n",
    "        \"\"\"\n",
    "        Load image data and resize image if 'resize'=True.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        path_liist : np.ndarray\n",
    "            The array of relative image paths from directory 'dir_name'.\n",
    "            Size of this array is 'batch_size'.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        img_list : np.ndarray\n",
    "            The array of image data.\n",
    "            Size of an image is (width, height, 3) if 'resize'=True.\n",
    "        '\"\"\"\n",
    "        img_list = []\n",
    "        for path in path_list:\n",
    "            img = cv2.imread(path)\n",
    "            img = cv2.resize(img, (self.width, self.height))\n",
    "            img = img / 255.\n",
    "            img_list.append(img)\n",
    "\n",
    "        img_list = np.array(img_list)\n",
    "        return img_list\n",
    "\n",
    "    def _shuffle(self):\n",
    "        \"\"\"\n",
    "        Shuffle path_list, meta model.\n",
    "        If 'is_train' is True, target is shuffled in association path_list.\n",
    "        \"\"\"\n",
    "        idx = np.random.permutation(len(self.path_list))\n",
    "        self.path_list = self.path_list[idx]\n",
    "        self.meta_data = self.meta_data[idx]\n",
    "        if self.is_train:\n",
    "            self.target = self.target[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path_list = self.path_list[self.batch_size*idx:self.batch_size*(idx+1)]\n",
    "        meta = self.meta_data[self.batch_size*idx:self.batch_size*(idx+1)]\n",
    "        img_list = self.get_img(path_list)\n",
    "        if self.is_train:\n",
    "            target_list = self.target[self.batch_size*idx:self.batch_size*(idx+1)]\n",
    "\n",
    "            return (img_list, meta), target_list\n",
    "        else:\n",
    "            return ((img_list, meta),)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.is_train:\n",
    "            self._shuffle()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab18eb9-6e4f-40f8-9ffc-c2b394b47870",
   "metadata": {},
   "source": [
    "### Create model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae81ae9f-aead-43ec-9c7b-906a40574366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape: Tuple[int], meta_shape: int,\n",
    "                 output_shape: int, activation, loss,\n",
    "                 learning_rate: float = 0.001,\n",
    "                 pretrain: bool = False) -> models.Model:\n",
    "    \"\"\"\n",
    "    The function for creating model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_shape : int\n",
    "        Shape of input image data.\n",
    "    meta_shape : int\n",
    "        Shape of input meta data of image.\n",
    "    output_shape : int\n",
    "        Shape of model output.\n",
    "    activation : function\n",
    "        The activation function used hidden layers.\n",
    "    loss : function\n",
    "        The loss function of model.\n",
    "    learning_rate : float\n",
    "        The learning rate of model.\n",
    "    pretrain : bool\n",
    "        Flag that deterimine whether use pretrain model(default=False).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model : keras.models.Model\n",
    "        Model instance.\n",
    "    \"\"\"\n",
    "    if pretrain:\n",
    "        weights = 'imagenet'\n",
    "    else:\n",
    "        weights = None\n",
    "\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    efn_model = efn(include_top=False, input_shape=input_shape,\n",
    "                    weights=weights)(inputs)\n",
    "    ga = layers.GlobalAveragePooling2D()(efn_model)\n",
    "\n",
    "    meta_inputs = layers.Input(shape=meta_shape)\n",
    "    concate = layers.Concatenate()([ga, meta_inputs])\n",
    "    dense1 = layers.Dense(units=128)(concate)\n",
    "    bn1 = layers.BatchNormalization()(dense1)\n",
    "    av1 = layers.Activation(activation)(bn1)\n",
    "    dense2 = layers.Dense(units=64)(av1)\n",
    "    bn2 = layers.BatchNormalization()(dense2)\n",
    "    av2 = layers.Activation(activation)(bn2)\n",
    "    outputs = layers.Dense(output_shape)(av2)\n",
    "\n",
    "    model = models.Model(inputs=[inputs, meta_inputs], outputs=[outputs])\n",
    "    model.compile(loss=loss,\n",
    "                  optimizer=optim.SGD(learning_rate=learning_rate, momentum=0.9),\n",
    "                  metrics=['mae', 'mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d8ef5c-83cf-4e06-a76a-ebac170eab62",
   "metadata": {},
   "source": [
    "### Training model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d69c795d-f36c-45e1-88b4-f3c591e4f372",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(path_list: np.ndarray, meta_data: np.ndarray,\n",
    "          target: np.ndarray, loss):\n",
    "    \"\"\"\n",
    "    The function for training model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path_list : np.ndarray\n",
    "        The path list of all image data.\n",
    "    meta_data : np.ndarray\n",
    "        The array of meta data of image.\n",
    "    target : np.ndarray\n",
    "        The array of targets data.\n",
    "    loss : function\n",
    "        The loss function of keras.\n",
    "    \"\"\"\n",
    "    train_path, val_path, train_meta, val_meta, train_y, val_y =\\\n",
    "        train_test_split(path_list, meta_data, target, test_size=0.1, random_state=6174)\n",
    "\n",
    "    train_gen = FullPathDataLoader(path_list=train_path,\n",
    "                                   meta_data=train_meta, target=train_y,\n",
    "                                   batch_size=16)\n",
    "    val_gen = FullPathDataLoader(path_list=val_path,\n",
    "                                 meta_data=val_meta, target=val_y,\n",
    "                                 batch_size=1)\n",
    "    model = NFTModel(\n",
    "        create_model(input_shape=(256, 256, 3), meta_shape=len(meta_features),\n",
    "                     output_shape=1, activation=activations.relu,\n",
    "                     loss=loss, learning_rate=0.0001,\n",
    "                     pretrain=True)\n",
    "    )\n",
    "\n",
    "    ES = callbacks.EarlyStopping(monitor='val_loss', patience=5,\n",
    "                                 restore_best_weights=True)\n",
    "\n",
    "    print(\"starting training\")\n",
    "    print('*' + '-' * 30 + '*')\n",
    "\n",
    "    model.fit(train_gen, val_gen, epochs=100, batch_size=16,\n",
    "              callbacks=[ES])\n",
    "\n",
    "    print(\"finished training\")\n",
    "    print('*' + '-' * 30 + '*' + '\\n')\n",
    "\n",
    "    val_gen = FullPathDataLoader(path_list=val_path,\n",
    "                                 meta_data=val_meta, target=val_y,\n",
    "                                 batch_size=1, shuffle=False, is_train=False)\n",
    "    print(\"starting evaluate\")\n",
    "    print('*' + '-' * 30 + '*')\n",
    "\n",
    "    model.evaluate(val_gen, val_y)\n",
    "\n",
    "    print(\"finished evaluate\")\n",
    "    print('*' + '-' * 30 + '*' + '\\n')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8611a18a-51e3-4841-ac3b-3b3400d8ff2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NFTModel(KerasRegressor):\n",
    "    \"\"\"\n",
    "    Model class.\n",
    "    This class is inherited KerasRegressor class of keras.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_func):\n",
    "        \"\"\"\n",
    "        Constructor.\n",
    "\n",
    "        Prameters\n",
    "        ---------\n",
    "        model_func : function\n",
    "            The function for creating model.\n",
    "        \"\"\"\n",
    "        super().__init__(build_fn=model_func)\n",
    "\n",
    "    def __getstate__(self):\n",
    "        result = {'sk_params': self.sk_params}\n",
    "        with tempfile.TemporaryDirectory() as dir:\n",
    "            if hasattr(self, 'model'):\n",
    "                self.model.save(dir + '/output.h5', include_optimizer=False)\n",
    "                with open(dir + '/output.h5', 'rb') as f:\n",
    "                    result['model'] = f.read()\n",
    "        return result\n",
    "\n",
    "    def __setstate__(self, serialized):\n",
    "        self.sk_params = serialized['sk_params']\n",
    "        with tempfile.TemporaryDirectory() as dir:\n",
    "            model_data = serialized.get('model')\n",
    "            if model_data:\n",
    "                with open(dir + '/input.h5', 'wb') as f:\n",
    "                    f.write(model_data)\n",
    "                self.model = tf.keras.models.load_model(dir + '/input.h5')\n",
    "\n",
    "    def fit(self, train_gen, val_gen, epochs, batch_size, callbacks):\n",
    "        \"\"\"\n",
    "        Training model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        train_gen : iterator\n",
    "            The generator of train data.\n",
    "        val_gen : iterator\n",
    "            The generator of validation data.\n",
    "        epochs : int\n",
    "            Number of epochs for training model.\n",
    "        batch_size : int\n",
    "            Size of batch for training model.\n",
    "        callbacks : list\n",
    "            The list of callbacks.\n",
    "            For example [EarlyStopping instance, ModelCheckpoint instance]\n",
    "        \"\"\"\n",
    "        self.model = self.build_fn\n",
    "        self.model.fit(train_gen, epochs=epochs, batch_size=batch_size,\n",
    "                       validation_data=val_gen, callbacks=callbacks)\n",
    "\n",
    "    def evaluate(self, test_X, test_y):\n",
    "        \"\"\"\n",
    "        Evaluate model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        test_X : iterator\n",
    "            The generator of test data.\n",
    "        test_y : np.ndarray\n",
    "            The array of targets of test data.\n",
    "        \"\"\"\n",
    "        pred = self.model.predict(test_X)\n",
    "        pred = np.where(pred < 0, 0, pred)\n",
    "        rmse = np.sqrt(mean_squared_error(test_y, pred))\n",
    "        mae = np.sqrt(mean_absolute_error(test_y, pred))\n",
    "\n",
    "        print(f\"RMSE Score: {rmse}\")\n",
    "        print(f\"MAE Score: {mae}\")\n",
    "\n",
    "    def predict(self, img_path: str, collection_name: str, num_sales: int):\n",
    "        \"\"\"\n",
    "        Predict data using trained model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        img_path : str\n",
    "            The path of image data.\n",
    "        collection_name : str\n",
    "            Name of collection of the NFT.\n",
    "        num_sales : int\n",
    "            Number of times the NFT sold.\n",
    "        \"\"\"\n",
    "        collection_dict = {\n",
    "             'Axie': 0,\n",
    "             'BoredApeYachtClub': 1,\n",
    "             'CryptoPunks': 2,\n",
    "             'CyberKongz': 3,\n",
    "             'Doodles': 4,\n",
    "             'GalaxyEggs': 5,\n",
    "             'Jungle Freaks': 6,\n",
    "             'KaijuKingz': 7,\n",
    "             'Sneaky Vampire Syndicate': 8\n",
    "        }\n",
    "        meta_data = np.zeros(shape=(len(collection_dict)+1))\n",
    "        if collection_name in collection_dict.keys():\n",
    "            meta_data[collection_dict[collection_name]] = 1\n",
    "        meta_data[-1] = num_sales\n",
    "        meta_data = meta_data.reshape(1, -1)\n",
    "\n",
    "        img = cv2.resize(cv2.imread(img_path)/256., (256, 256))\n",
    "        img = img.reshape(1, 256, 256, 3)\n",
    "\n",
    "        pred = self.model.predict([img, meta_data])\n",
    "        return pred[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "184a4688-00bf-47b8-8e57-635cb9f0f4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(instance, file_name: str):\n",
    "    \"\"\"\n",
    "    Save model as pickle file\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    instance : Class instance\n",
    "        The class instance you want to save as pickle file.\n",
    "    file_name : str\n",
    "        The absolute path of file saved the instance.\n",
    "    \"\"\"\n",
    "    with open(file_name, mode='wb') as f:\n",
    "        cloudpickle.dump(instance, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9261d8b-47c3-4e1c-8bfa-f98763d74a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(file_name: str):\n",
    "    \"\"\"\n",
    "    Load the model file of pickle.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_name : str\n",
    "        The absolute path of the model file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model : tf.keras.models.Model\n",
    "        Trained model object.\n",
    "    \"\"\"\n",
    "    with open(file_name, mode='rb') as f:\n",
    "        model = cloudpickle.load(f)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b4cb72-e675-4a37-93d2-c76038d38b58",
   "metadata": {},
   "source": [
    "## Training models  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3837f2-893c-4766-b986-38c62827e53b",
   "metadata": {},
   "source": [
    "### TaskA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad0327f9-d21b-4b89-b863-43c45eec513b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training\n",
      "*------------------------------*\n",
      "Epoch 1/100\n",
      "2331/2331 [==============================] - 725s 308ms/step - loss: 0.6283 - mae: 0.5841 - mse: 0.6283 - val_loss: 81.7752 - val_mae: 5.9429 - val_mse: 81.7752\n",
      "Epoch 2/100\n",
      "2331/2331 [==============================] - 720s 309ms/step - loss: 0.2921 - mae: 0.3942 - mse: 0.2921 - val_loss: 0.6297 - val_mae: 0.5397 - val_mse: 0.6297\n",
      "Epoch 3/100\n",
      "2331/2331 [==============================] - 716s 307ms/step - loss: 0.2516 - mae: 0.3599 - mse: 0.2516 - val_loss: 0.6645 - val_mae: 0.5358 - val_mse: 0.6645\n",
      "Epoch 4/100\n",
      "2331/2331 [==============================] - 713s 306ms/step - loss: 0.2249 - mae: 0.3382 - mse: 0.2249 - val_loss: 0.6539 - val_mae: 0.5350 - val_mse: 0.6539\n",
      "Epoch 5/100\n",
      "2331/2331 [==============================] - 715s 307ms/step - loss: 0.2125 - mae: 0.3218 - mse: 0.2125 - val_loss: 0.6203 - val_mae: 0.5305 - val_mse: 0.6203\n",
      "Epoch 6/100\n",
      "2331/2331 [==============================] - 715s 307ms/step - loss: 0.1917 - mae: 0.3083 - mse: 0.1917 - val_loss: 0.4788 - val_mae: 0.4664 - val_mse: 0.4788\n",
      "Epoch 7/100\n",
      "2331/2331 [==============================] - 717s 307ms/step - loss: 0.1800 - mae: 0.3011 - mse: 0.1800 - val_loss: 0.6055 - val_mae: 0.4897 - val_mse: 0.6055\n",
      "Epoch 8/100\n",
      "2331/2331 [==============================] - 717s 308ms/step - loss: 0.1790 - mae: 0.2982 - mse: 0.1790 - val_loss: 0.4721 - val_mae: 0.4480 - val_mse: 0.4721\n",
      "Epoch 9/100\n",
      "2331/2331 [==============================] - 688s 295ms/step - loss: 0.1703 - mae: 0.2898 - mse: 0.1703 - val_loss: 0.4765 - val_mae: 0.4188 - val_mse: 0.4765\n",
      "Epoch 10/100\n",
      "2331/2331 [==============================] - 713s 306ms/step - loss: 0.1651 - mae: 0.2863 - mse: 0.1651 - val_loss: 12.7009 - val_mae: 1.7883 - val_mse: 12.7009\n",
      "Epoch 11/100\n",
      "2331/2331 [==============================] - 717s 308ms/step - loss: 0.1577 - mae: 0.2815 - mse: 0.1577 - val_loss: 0.4149 - val_mae: 0.4127 - val_mse: 0.4149\n",
      "Epoch 12/100\n",
      "2331/2331 [==============================] - 718s 308ms/step - loss: 0.1467 - mae: 0.2693 - mse: 0.1467 - val_loss: 0.5639 - val_mae: 0.4921 - val_mse: 0.5639\n",
      "Epoch 13/100\n",
      "2331/2331 [==============================] - 716s 307ms/step - loss: 0.1543 - mae: 0.2758 - mse: 0.1543 - val_loss: 0.5914 - val_mae: 0.5097 - val_mse: 0.5914\n",
      "Epoch 14/100\n",
      "2331/2331 [==============================] - 714s 306ms/step - loss: 0.1478 - mae: 0.2706 - mse: 0.1478 - val_loss: 0.1626 - val_mae: 0.2479 - val_mse: 0.1626\n",
      "Epoch 15/100\n",
      "2331/2331 [==============================] - 720s 309ms/step - loss: 0.1521 - mae: 0.2735 - mse: 0.1521 - val_loss: 0.3507 - val_mae: 0.3748 - val_mse: 0.3507\n",
      "Epoch 16/100\n",
      "2331/2331 [==============================] - 719s 308ms/step - loss: 0.1429 - mae: 0.2657 - mse: 0.1429 - val_loss: 0.3687 - val_mae: 0.3911 - val_mse: 0.3687\n",
      "Epoch 17/100\n",
      "2331/2331 [==============================] - 718s 308ms/step - loss: 0.1365 - mae: 0.2607 - mse: 0.1365 - val_loss: 0.4497 - val_mae: 0.4075 - val_mse: 0.4497\n",
      "Epoch 18/100\n",
      "2331/2331 [==============================] - 717s 308ms/step - loss: 0.1344 - mae: 0.2583 - mse: 0.1344 - val_loss: 0.4204 - val_mae: 0.4039 - val_mse: 0.4204\n",
      "Epoch 19/100\n",
      "2331/2331 [==============================] - 718s 308ms/step - loss: 0.1332 - mae: 0.2566 - mse: 0.1332 - val_loss: 0.5479 - val_mae: 0.4660 - val_mse: 0.5479\n",
      "finished training\n",
      "*------------------------------*\n",
      "\n",
      "starting evaluate\n",
      "*------------------------------*\n",
      "RMSE Score: 0.4018617327000809\n",
      "MAE Score: 0.49533075082790257\n",
      "finished evaluate\n",
      "*------------------------------*\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashme/anaconda3/envs/ML/lib/python3.9/site-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    }
   ],
   "source": [
    "meta_features = ['Axie', 'BoredApeYachtClub', 'CryptoPunks', 'CyberKongz',\n",
    "                 'Doodles', 'GalaxyEggs', 'Jungle Freaks', 'KaijuKingz',\n",
    "                 'Sneaky Vampire Syndicate', 'num_sales']\n",
    "\n",
    "path_list = np.vstack(\n",
    "    (asset_df_A['full_path'].values.reshape(-1, 1),\n",
    "     asset_df_B['full_path'].values.reshape(-1, 1))\n",
    ").reshape(-1)\n",
    "meta_data = np.vstack(\n",
    "    (asset_df_A[meta_features].values.reshape(-1, 10),\n",
    "     asset_df_B[meta_features].values.reshape(-1, 10))\n",
    ")\n",
    "target = np.vstack(\n",
    "    (asset_df_A['current_price'].values.reshape(-1, 1),\n",
    "     asset_df_B['current_price'].values.reshape(-1, 1))\n",
    ").reshape(-1)\n",
    "\n",
    "model_A = train(path_list, meta_data, target, losses.mean_squared_error)\n",
    "save_model(model_A, \"baselineA.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87444d2c-ae2a-4cc6-9776-6ab420b16ed4",
   "metadata": {},
   "source": [
    "### TaskB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abcc6969-e9b1-4aed-bde1-22975d18fb10",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training\n",
      "*------------------------------*\n",
      "Epoch 1/100\n",
      "2098/2098 [==============================] - 660s 312ms/step - loss: 0.5206 - mae: 0.5403 - mse: 0.5206 - val_loss: 0.3162 - val_mae: 0.4170 - val_mse: 0.3162\n",
      "Epoch 2/100\n",
      "2098/2098 [==============================] - 652s 311ms/step - loss: 0.2208 - mae: 0.3474 - mse: 0.2208 - val_loss: 1.0513 - val_mae: 0.5986 - val_mse: 1.0513\n",
      "Epoch 3/100\n",
      "2098/2098 [==============================] - 651s 310ms/step - loss: 0.1760 - mae: 0.3062 - mse: 0.1760 - val_loss: 0.5062 - val_mae: 0.5047 - val_mse: 0.5062\n",
      "Epoch 4/100\n",
      "2098/2098 [==============================] - 631s 301ms/step - loss: 0.1640 - mae: 0.2886 - mse: 0.1640 - val_loss: 0.2971 - val_mae: 0.4153 - val_mse: 0.2971\n",
      "Epoch 5/100\n",
      "2098/2098 [==============================] - 652s 311ms/step - loss: 0.1558 - mae: 0.2752 - mse: 0.1558 - val_loss: 0.2410 - val_mae: 0.3555 - val_mse: 0.2410\n",
      "Epoch 6/100\n",
      "2098/2098 [==============================] - 653s 311ms/step - loss: 0.1404 - mae: 0.2639 - mse: 0.1404 - val_loss: 7.1460 - val_mae: 0.8438 - val_mse: 7.1460\n",
      "Epoch 7/100\n",
      "2098/2098 [==============================] - 647s 309ms/step - loss: 0.1276 - mae: 0.2547 - mse: 0.1276 - val_loss: 0.3065 - val_mae: 0.4046 - val_mse: 0.3065\n",
      "Epoch 8/100\n",
      "2098/2098 [==============================] - 653s 311ms/step - loss: 0.1299 - mae: 0.2529 - mse: 0.1299 - val_loss: 0.2740 - val_mae: 0.3856 - val_mse: 0.2740\n",
      "Epoch 9/100\n",
      "2098/2098 [==============================] - 652s 311ms/step - loss: 0.1241 - mae: 0.2448 - mse: 0.1241 - val_loss: 0.2607 - val_mae: 0.4084 - val_mse: 0.2607\n",
      "Epoch 10/100\n",
      "2098/2098 [==============================] - 656s 313ms/step - loss: 0.1202 - mae: 0.2411 - mse: 0.1202 - val_loss: 0.4412 - val_mae: 0.4905 - val_mse: 0.4412\n",
      "finished training\n",
      "*------------------------------*\n",
      "\n",
      "starting evaluate\n",
      "*------------------------------*\n",
      "RMSE Score: 0.49029559212232304\n",
      "MAE Score: 0.5953397811425521\n",
      "finished evaluate\n",
      "*------------------------------*\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashme/anaconda3/envs/ML/lib/python3.9/site-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    }
   ],
   "source": [
    "path_list = asset_df_B['full_path'].values\n",
    "meta_data = asset_df_B[meta_features].values\n",
    "target = asset_df_B['current_price'].values\n",
    "\n",
    "model_B = train(path_list, meta_data, target, losses.mean_squared_error)\n",
    "save_model(model_B, \"baselineB.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c4e02b-f661-43bc-9ec9-ef0f4d627d73",
   "metadata": {},
   "source": [
    "## Evaluate model  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2302c3d7-1051-4c23-8717-aba374fd0d01",
   "metadata": {},
   "source": [
    "### Task A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc482f19-9206-4817-b2ba-f2bff120e1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "RMSE Score: 0.4018617327000809\n",
      "MAE Score: 0.49533075082790257\n"
     ]
    }
   ],
   "source": [
    "file_name = \"baselineA.pkl\"\n",
    "model = load_model(file_name)\n",
    "\n",
    "meta_features = ['Axie', 'BoredApeYachtClub', 'CryptoPunks', 'CyberKongz',\n",
    "                 'Doodles', 'GalaxyEggs', 'Jungle Freaks', 'KaijuKingz',\n",
    "                 'Sneaky Vampire Syndicate', 'num_sales']\n",
    "\n",
    "path_list = np.vstack(\n",
    "    (asset_df_A['full_path'].values.reshape(-1, 1),\n",
    "     asset_df_B['full_path'].values.reshape(-1, 1))\n",
    ").reshape(-1)\n",
    "meta_data = np.vstack(\n",
    "    (asset_df_A[meta_features].values.reshape(-1, 10),\n",
    "     asset_df_B[meta_features].values.reshape(-1, 10))\n",
    ")\n",
    "target = np.vstack(\n",
    "    (asset_df_A['current_price'].values.reshape(-1, 1),\n",
    "     asset_df_B['current_price'].values.reshape(-1, 1))\n",
    ").reshape(-1)\n",
    "\n",
    "train_path, val_path, train_meta, val_meta, train_y, val_y =\\\n",
    "    train_test_split(path_list, meta_data, target, test_size=0.1, random_state=6174)\n",
    "\n",
    "val_gen = FullPathDataLoader(path_list=val_path,\n",
    "                             meta_data=val_meta, target=val_y,\n",
    "                             batch_size=1, shuffle=False, is_train=False)\n",
    "\n",
    "model.evaluate(val_gen, val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c61d60-b0ad-4ffa-8568-debe83ba19eb",
   "metadata": {},
   "source": [
    "### Task B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68e89386-5031-48f4-8ded-7112b64eb462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "RMSE Score: 0.49029559212232304\n",
      "MAE Score: 0.5953397811425521\n"
     ]
    }
   ],
   "source": [
    "file_name = \"baselineB.pkl\"\n",
    "model = load_model(file_name)\n",
    "\n",
    "path_list = asset_df_B['full_path'].values\n",
    "meta_data = asset_df_B[meta_features].values\n",
    "target = asset_df_B['current_price'].values\n",
    "\n",
    "train_path, val_path, train_meta, val_meta, train_y, val_y =\\\n",
    "    train_test_split(path_list, meta_data, target, test_size=0.1, random_state=6174)\n",
    "\n",
    "val_gen = FullPathDataLoader(path_list=val_path,\n",
    "                             meta_data=val_meta, target=val_y,\n",
    "                             batch_size=1, shuffle=False, is_train=False)\n",
    "\n",
    "model.evaluate(val_gen, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87627221-a503-49cc-8210-054078815218",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
