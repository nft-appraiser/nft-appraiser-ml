{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b83eaf3b-a15b-42fd-99da-dc9e6950f7bd",
   "metadata": {},
   "source": [
    "# 価格予測モデルのBaseline  \n",
    "- CNNを用いたモデルを作成する．  \n",
    "- 価格予測とクラス分類でタスクが大きく異なるので，imagenetで学習したモデルを用いないものを最初に作成する．  \n",
    "- サイトに載せられる画像を教師データとしており，画像が大きく回転したりなどは不要と考えられるためそのような前処理は行わない．  \n",
    "- 損失関数にはmaeもしくはrmseを用いる．  \n",
    "\n",
    "## モデルの構築  \n",
    "- EfficientNetB0（未学習）を用いて特徴量を抽出．  \n",
    "- num_sales, コレクション名のone-hotベクトルを抽出した特徴量に結合．  \n",
    "- 全結合層を重ねて出力．  \n",
    "- ImageNetを用いて事前学習したものとしていないもので比較する．  \n",
    "- 目的変数をそのまま予測するとスケールが大きすぎるので，先に対数変換して評価関数にRMSE, MAEなどを用いるほうが良いかも．  \n",
    "- **このノートブックでやっているのは事前学習有り．**  \n",
    "\n",
    "## 評価関数  \n",
    "- RMSLEを用いる．  \n",
    "$$RMSLE = \\sqrt{\\frac{1}{n}\\sum_{i=1}^n (\\log{(y_i+1)} - \\log{(\\hat{y_i} +1)})^2}$$\n",
    "\n",
    "- 追加でMAPEを用いてみる．  \n",
    "$$MAPE = \\frac{100}{n} \\sum_{i=1}^n |\\frac{\\hat{y}_i - y_i}{y_i}|$$\n",
    "\n",
    "タスクAに関してはデータ不足の可能性が考えられるため，特徴量抽出とともにデータを追加で収集する．  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcd6e453-d7a2-447a-94c2-e3e41e7c841e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import List, Optional, Tuple, Dict\n",
    "import math\n",
    "import tempfile\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.models as models\n",
    "import tensorflow.keras.losses as losses\n",
    "import tensorflow.keras.optimizers as optim\n",
    "import tensorflow.keras.activations as activations\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "import tensorflow.keras.callbacks as callbacks\n",
    "from tensorflow.keras.applications import EfficientNetB0 as efn\n",
    "import cloudpickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1adc001b-4234-4ec3-9b9d-b23a47cca243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: (1494, 12)\n",
      "data shape: (209, 18)\n"
     ]
    }
   ],
   "source": [
    "A_IMGPATH = \"../data/taskA/img\"\n",
    "A_DFPATH = \"../data/taskA/table\"\n",
    "B_IMGPATH = \"../data/taskB/img\"\n",
    "B_DFPATH = \"../data/taskB/table\"\n",
    "asset_df_A = pd.read_csv(os.path.join(A_DFPATH, \"asset_data.csv\"))\n",
    "asset_df_B = pd.read_csv(os.path.join(B_DFPATH, \"asset_data.csv\"))\n",
    "\n",
    "asset_df_A = pd.concat((asset_df_A, pd.get_dummies(asset_df_A['asset_contract.name'])), axis=1)\n",
    "asset_df_B[asset_df_A.columns.values[8:]] = 0\n",
    "asset_df_B = asset_df_B.rename(columns={\"asset.num_sales\": \"num_sales\"})\n",
    "asset_df_A = asset_df_A.rename(columns={\"last_sale.total_price\": \"current_price\"})\n",
    "asset_df_A['current_price'] = asset_df_A['current_price'].astype(float)\n",
    "\n",
    "asset_df_A[\"full_path\"] =\\\n",
    "    asset_df_A[\"image_id\"].apply(lambda x: A_IMGPATH + \"/\" + x)\n",
    "asset_df_B[\"full_path\"] =\\\n",
    "    asset_df_B[\"image_id\"].apply(lambda x: B_IMGPATH + \"/\" + x)\n",
    "asset_df_A['current_price'] = asset_df_A['current_price'] * 1e-18\n",
    "asset_df_B['current_price'] = asset_df_B['current_price'] * 1e-18\n",
    "asset_df_A = asset_df_A.query('current_price > 0')\n",
    "asset_df_B = asset_df_B.query('current_price > 0')\n",
    "asset_df_A['current_price'] = asset_df_A['current_price'].apply(lambda x: np.log1p(x))\n",
    "asset_df_B['current_price'] = asset_df_B['current_price'].apply(lambda x: np.log1p(x))\n",
    "\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "\n",
    "print(f\"data shape: {asset_df_A.shape}\")\n",
    "print(f\"data shape: {asset_df_B.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd9128f-90a3-4a76-a850-c81273b9967d",
   "metadata": {},
   "source": [
    "## Helper Functions  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2126e4f-9af4-4b15-9bde-dc1a5f8a1124",
   "metadata": {},
   "source": [
    "### DataLoader  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "deb23666-1673-4db8-85da-9f8aa0fcbd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullPathDataLoader(Sequence):\n",
    "    \"\"\"\n",
    "    Data loader that load images, meta data and targets.\n",
    "    This class is inherited Sequence class of Keras.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path_list: np.ndarray, target: Optional[np.ndarray],\n",
    "                 meta_data: Optional[np.ndarray] = None, batch_size: int = 16,\n",
    "                 task: str = \"B\", width: int = 256, height: int = 256,\n",
    "                 resize: bool = True, shuffle: bool = True, is_train: bool = True):\n",
    "        \"\"\"\n",
    "        Constructor. This method determines class variables.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        path_list : np.ndarray[str]\n",
    "            The array of absolute paths of images.\n",
    "        meta_data : np.ndarray[int]\n",
    "            One-hot vector of collections.\n",
    "        target : np.ndarray\n",
    "            Array of target variavles.\n",
    "        batch_size : int\n",
    "            Batch size used when model training.\n",
    "        task : str\n",
    "            Please determine this data loader will be used for task A or B(default=A).\n",
    "        width : int\n",
    "            Width of resized image.\n",
    "        height : int\n",
    "            Height of resize image.\n",
    "        resize : bool\n",
    "            Flag determine whether to resize.\n",
    "        shuffle : bool\n",
    "            Flag determine whether to shuffle on epoch end.\n",
    "        is_train : bool\n",
    "            Determine whether this data loader will be used training model.\n",
    "            if you won't this data loader, you have set 'is_train'=False.\n",
    "        \"\"\"\n",
    "        self.path_list = path_list\n",
    "        self.batch_size = batch_size\n",
    "        self.task = task\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.resize = resize\n",
    "        self.shuffle = shuffle\n",
    "        self.is_train = is_train\n",
    "        self.length = math.ceil(len(self.path_list) / self.batch_size)\n",
    "\n",
    "        if self.is_train:\n",
    "            self.target = target\n",
    "        if self.task == \"A\":\n",
    "            self.meta_data = meta_data\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns\n",
    "        -------\n",
    "        self.length : data length\n",
    "        \"\"\"\n",
    "        return self.length\n",
    "\n",
    "    def get_img(self, path_list: np.ndarray):\n",
    "        \"\"\"\n",
    "        Load image data and resize image if 'resize'=True.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        path_liist : np.ndarray\n",
    "            The array of relative image paths from directory 'dir_name'.\n",
    "            Size of this array is 'batch_size'.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        img_list : np.ndarray\n",
    "            The array of image data.\n",
    "            Size of an image is (width, height, 3) if 'resize'=True.\n",
    "        '\"\"\"\n",
    "        img_list = []\n",
    "        for path in path_list:\n",
    "            img = cv2.imread(path)\n",
    "            img = cv2.resize(img, (self.width, self.height))\n",
    "            img = img / 255.\n",
    "            img_list.append(img)\n",
    "\n",
    "        img_list = np.array(img_list)\n",
    "        return img_list\n",
    "\n",
    "    def _shuffle(self):\n",
    "        \"\"\"\n",
    "        Shuffle path_list, meta model.\n",
    "        If 'is_train' is True, target is shuffled in association path_list.\n",
    "        \"\"\"\n",
    "        idx = np.random.permutation(len(self.path_list))\n",
    "        self.path_list = self.path_list[idx]\n",
    "        if self.task == \"A\":\n",
    "            self.meta_data = self.meta_data[idx]\n",
    "        if self.is_train:\n",
    "            self.target = self.target[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path_list = self.path_list[self.batch_size*idx:self.batch_size*(idx+1)]\n",
    "        img_list = self.get_img(path_list)\n",
    "        if self.is_train:\n",
    "            target_list = self.target[self.batch_size*idx:self.batch_size*(idx+1)]\n",
    "            if self.task == \"A\":\n",
    "                meta = self.meta_data[self.batch_size*idx:self.batch_size*(idx+1)]\n",
    "                return (img_list, meta), target_list\n",
    "            else:\n",
    "                return img_list, target_list\n",
    "        else:\n",
    "            if self.task == \"A\":\n",
    "                meta = self.meta_data[self.batch_size*idx:self.batch_size*(idx+1)]\n",
    "                return ((img_list, meta),)\n",
    "            else:\n",
    "                return img_list\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.is_train:\n",
    "            self._shuffle()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccabc2f6-749f-404a-a617-9f0507113d78",
   "metadata": {},
   "source": [
    "### seed settings  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44fab9da-4ce3-4548-ba52-29baf9c5e2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(random_state=6174):\n",
    "    tf.random.set_seed(random_state)\n",
    "    np.random.seed(random_state)\n",
    "    random.seed(random_state)\n",
    "    os.environ['PYTHONHASHSEED'] = str(random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab18eb9-6e4f-40f8-9ffc-c2b394b47870",
   "metadata": {},
   "source": [
    "### Create model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae81ae9f-aead-43ec-9c7b-906a40574366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape: Tuple[int], output_shape: int,\n",
    "                 activation, loss, meta_shape: Optional[int] = None,\n",
    "                 task: str = \"B\", learning_rate: float = 0.001,\n",
    "                 pretrain: bool = False) -> models.Model:\n",
    "    \"\"\"\n",
    "    The function for creating model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_shape : int\n",
    "        Shape of input image data.\n",
    "    output_shape : int\n",
    "        Shape of model output.\n",
    "    activation : function\n",
    "        The activation function used hidden layers.\n",
    "    loss : function\n",
    "        The loss function of model.\n",
    "    meta_shape : int\n",
    "        Shape of input meta data of image.\n",
    "    task : str\n",
    "        Please determine this model will be used for task A or B(default=A).\n",
    "    learning_rate : float\n",
    "        The learning rate of model.\n",
    "    pretrain : bool\n",
    "        Flag that deterimine whether use pretrain model(default=False).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model : keras.models.Model\n",
    "        Model instance.\n",
    "    \"\"\"\n",
    "    if pretrain:\n",
    "        weights = 'imagenet'\n",
    "    else:\n",
    "        weights = None\n",
    "\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    efn_model = efn(include_top=False, input_shape=input_shape,\n",
    "                    weights=weights)(inputs)\n",
    "    ga = layers.GlobalAveragePooling2D()(efn_model)\n",
    "\n",
    "    if task == \"A\":\n",
    "        meta_inputs = layers.Input(shape=meta_shape)\n",
    "        concate = layers.Concatenate()([ga, meta_inputs])\n",
    "        dense1 = layers.Dense(units=128)(concate)\n",
    "        bn1 = layers.BatchNormalization()(dense1)\n",
    "        av1 = layers.Activation(activation)(bn1)\n",
    "        dense2 = layers.Dense(units=64)(av1)\n",
    "        bn2 = layers.BatchNormalization()(dense2)\n",
    "        av2 = layers.Activation(activation)(bn2)\n",
    "        outputs = layers.Dense(output_shape)(av2)\n",
    "        model = models.Model(inputs=[inputs, meta_inputs], outputs=[outputs])\n",
    "\n",
    "    elif task == \"B\":\n",
    "        dense1 = layers.Dense(units=128)(ga)\n",
    "        bn1 = layers.BatchNormalization()(dense1)\n",
    "        av1 = layers.Activation(activation)(bn1)\n",
    "        dense2 = layers.Dense(units=64)(av1)\n",
    "        bn2 = layers.BatchNormalization()(dense2)\n",
    "        av2 = layers.Activation(activation)(bn2)\n",
    "        outputs = layers.Dense(output_shape)(av2)\n",
    "\n",
    "        model = models.Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"Please set task is A or B.\")\n",
    "\n",
    "    model.compile(loss=loss,\n",
    "                  optimizer=optim.SGD(learning_rate=learning_rate, momentum=0.9),\n",
    "                  metrics=['mae', 'mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d8ef5c-83cf-4e06-a76a-ebac170eab62",
   "metadata": {},
   "source": [
    "### Training model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d69c795d-f36c-45e1-88b4-f3c591e4f372",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(path_list: np.ndarray, target: np.ndarray, loss,\n",
    "          meta_data: Optional[np.ndarray] = None, task: str = \"B\"):\n",
    "    \"\"\"\n",
    "    The function for training model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path_list : np.ndarray\n",
    "        The path list of all image data.\n",
    "    target : np.ndarray\n",
    "        The array of targets data.\n",
    "    loss : function\n",
    "        The loss function of keras.\n",
    "    meta_data : np.ndarray\n",
    "        The array of meta data of image.\n",
    "    task : str\n",
    "        Please determine you train model for task A or B(default=A).\n",
    "    \"\"\"\n",
    "    if task == \"A\":\n",
    "        train_path, val_path, train_meta, val_meta, train_y, val_y =\\\n",
    "            train_test_split(path_list, meta_data, target, test_size=0.1, random_state=6174)\n",
    "        train_gen = FullPathDataLoader(path_list=train_path, target=train_y,\n",
    "                                       meta_data=train_meta, batch_size=16,\n",
    "                                       task=task)\n",
    "        val_gen = FullPathDataLoader(path_list=val_path, target=train_y,\n",
    "                                     meta_data=val_meta, batch_size=1,\n",
    "                                     task=task)\n",
    "    elif task == \"B\":\n",
    "        train_path, val_path, train_y, val_y =\\\n",
    "            train_test_split(path_list, target, test_size=0.1, random_state=6174)\n",
    "        train_gen = FullPathDataLoader(path_list=train_path, target=train_y,\n",
    "                                       batch_size=16, task=task)\n",
    "        val_gen = FullPathDataLoader(path_list=val_path, target=val_y,\n",
    "                                     batch_size=1, task=task)\n",
    "    else:\n",
    "        raise Exception(\"Please set task is A or B\")\n",
    "\n",
    "    set_seed()\n",
    "    model = NFTModel(\n",
    "        create_model(input_shape=(256, 256, 3), output_shape=1,\n",
    "                     activation=activations.relu, loss=loss,\n",
    "                     meta_shape=len(meta_features), task=task,\n",
    "                     learning_rate=0.00001, pretrain=True)\n",
    "    )\n",
    "\n",
    "    ES = callbacks.EarlyStopping(monitor='val_loss', patience=5,\n",
    "                                 restore_best_weights=True)\n",
    "\n",
    "    print(\"starting training\")\n",
    "    print('*' + '-' * 30 + '*')\n",
    "\n",
    "    model.fit(train_gen, val_gen, epochs=100, batch_size=16,\n",
    "              callbacks=[ES])\n",
    "\n",
    "    print(\"finished training\")\n",
    "    print('*' + '-' * 30 + '*' + '\\n')\n",
    "\n",
    "    if task == \"A\":\n",
    "        val_gen = FullPathDataLoader(path_list=val_path, target=train_y,\n",
    "                                     meta_data=val_meta, batch_size=1, task=task,\n",
    "                                     shuffle=False, is_train=False)\n",
    "    else:\n",
    "        val_gen = FullPathDataLoader(path_list=val_path, target=train_y,\n",
    "                                     batch_size=1, task=task,\n",
    "                                     shuffle=False, is_train=False)\n",
    "    print(\"starting evaluate\")\n",
    "    print('*' + '-' * 30 + '*')\n",
    "\n",
    "    model.evaluate(val_gen, val_y)\n",
    "\n",
    "    print(\"finished evaluate\")\n",
    "    print('*' + '-' * 30 + '*' + '\\n')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8611a18a-51e3-4841-ac3b-3b3400d8ff2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NFTModel(KerasRegressor):\n",
    "    \"\"\"\n",
    "    Model class.\n",
    "    This class is inherited KerasRegressor class of keras.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_func):\n",
    "        \"\"\"\n",
    "        Constructor.\n",
    "\n",
    "        Prameters\n",
    "        ---------\n",
    "        model_func : function\n",
    "            The function for creating model.\n",
    "        \"\"\"\n",
    "        super().__init__(build_fn=model_func)\n",
    "\n",
    "    def __getstate__(self):\n",
    "        result = {'sk_params': self.sk_params}\n",
    "        with tempfile.TemporaryDirectory() as dir:\n",
    "            if hasattr(self, 'model'):\n",
    "                self.model.save(dir + '/output.h5', include_optimizer=False)\n",
    "                with open(dir + '/output.h5', 'rb') as f:\n",
    "                    result['model'] = f.read()\n",
    "        return result\n",
    "\n",
    "    def __setstate__(self, serialized):\n",
    "        self.sk_params = serialized['sk_params']\n",
    "        with tempfile.TemporaryDirectory() as dir:\n",
    "            model_data = serialized.get('model')\n",
    "            if model_data:\n",
    "                with open(dir + '/input.h5', 'wb') as f:\n",
    "                    f.write(model_data)\n",
    "                self.model = tf.keras.models.load_model(dir + '/input.h5')\n",
    "\n",
    "    def fit(self, train_gen, val_gen, epochs, batch_size, callbacks):\n",
    "        \"\"\"\n",
    "        Training model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        train_gen : iterator\n",
    "            The generator of train data.\n",
    "        val_gen : iterator\n",
    "            The generator of validation data.\n",
    "        epochs : int\n",
    "            Number of epochs for training model.\n",
    "        batch_size : int\n",
    "            Size of batch for training model.\n",
    "        callbacks : list\n",
    "            The list of callbacks.\n",
    "            For example [EarlyStopping instance, ModelCheckpoint instance]\n",
    "        \"\"\"\n",
    "        self.model = self.build_fn\n",
    "        self.model.fit(train_gen, epochs=epochs, batch_size=batch_size,\n",
    "                       validation_data=val_gen, callbacks=callbacks)\n",
    "\n",
    "    def evaluate(self, test_X, test_y):\n",
    "        \"\"\"\n",
    "        Evaluate model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        test_X : iterator\n",
    "            The generator of test data.\n",
    "        test_y : np.ndarray\n",
    "            The array of targets of test data.\n",
    "        \"\"\"\n",
    "        pred = self.model.predict(test_X)\n",
    "        pred = np.where(pred < 0, 0, pred)\n",
    "        rmse = np.sqrt(mean_squared_error(test_y, pred))\n",
    "        mae = np.sqrt(mean_absolute_error(test_y, pred))\n",
    "\n",
    "        print(f\"RMSE Score: {rmse}\")\n",
    "        print(f\"MAE Score: {mae}\")\n",
    "\n",
    "    def predict(self, img_path: str, collection_name: str, num_sales: int,\n",
    "                task: str = \"B\"):\n",
    "        \"\"\"\n",
    "        Predict data using trained model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        img_path : str\n",
    "            The path of image data.\n",
    "        collection_name : str\n",
    "            Name of collection of the NFT.\n",
    "        num_sales : int\n",
    "            Number of times the NFT sold.\n",
    "        \"\"\"\n",
    "        if task == \"A\":\n",
    "            collection_dict = {\n",
    "                 'BoredApeYachtClub': 0,\n",
    "                 'CryptoPunks': 1,\n",
    "                 'Doodles': 2,\n",
    "            }\n",
    "            meta_data = np.zeros(shape=(len(collection_dict)+1))\n",
    "            if collection_name in collection_dict.keys():\n",
    "                meta_data[collection_dict[collection_name]] = 1\n",
    "            meta_data[-1] = num_sales\n",
    "            meta_data = meta_data.reshape(1, -1)\n",
    "\n",
    "            img = cv2.resize(cv2.imread(img_path)/256., (256, 256))\n",
    "            img = img.reshape(1, 256, 256, 3)\n",
    "\n",
    "            pred = self.model.predict([img, meta_data])\n",
    "        elif task == \"B\":\n",
    "            img = cv2.resize(cv2.imread(img_path)/256., (256, 256))\n",
    "            img = img.reshape(1, 256, 256, 3)\n",
    "\n",
    "            pred = self.model.predict(img)\n",
    "        else:\n",
    "            raise Exception(\"Please set task is A or B\")\n",
    "\n",
    "        return pred[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "184a4688-00bf-47b8-8e57-635cb9f0f4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(instance, file_name: str):\n",
    "    \"\"\"\n",
    "    Save model as pickle file\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    instance : Class instance\n",
    "        The class instance you want to save as pickle file.\n",
    "    file_name : str\n",
    "        The absolute path of file saved the instance.\n",
    "    \"\"\"\n",
    "    with open(file_name, mode='wb') as f:\n",
    "        cloudpickle.dump(instance, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9261d8b-47c3-4e1c-8bfa-f98763d74a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(file_name: str):\n",
    "    \"\"\"\n",
    "    Load the model file of pickle.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_name : str\n",
    "        The absolute path of the model file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model : tf.keras.models.Model\n",
    "        Trained model object.\n",
    "    \"\"\"\n",
    "    with open(file_name, mode='rb') as f:\n",
    "        model = cloudpickle.load(f)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b4cb72-e675-4a37-93d2-c76038d38b58",
   "metadata": {},
   "source": [
    "## Training models  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3837f2-893c-4766-b986-38c62827e53b",
   "metadata": {},
   "source": [
    "### TaskA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad0327f9-d21b-4b89-b863-43c45eec513b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training\n",
      "*------------------------------*\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 33s 290ms/step - loss: 10.8352 - mae: 2.9184 - mse: 10.8352 - val_loss: 7.7028 - val_mae: 2.1999 - val_mse: 7.7028\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 27s 283ms/step - loss: 7.4712 - mae: 2.4698 - mse: 7.4712 - val_loss: 5.7241 - val_mae: 1.8856 - val_mse: 5.7241\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 27s 283ms/step - loss: 4.9158 - mae: 1.9658 - mse: 4.9158 - val_loss: 3.6084 - val_mae: 1.7240 - val_mse: 3.6084\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - 27s 284ms/step - loss: 3.3727 - mae: 1.5848 - mse: 3.3727 - val_loss: 4.8803 - val_mae: 1.8605 - val_mse: 4.8803\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 27s 284ms/step - loss: 2.2544 - mae: 1.2402 - mse: 2.2544 - val_loss: 3.9603 - val_mae: 1.6954 - val_mse: 3.9603\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - 27s 284ms/step - loss: 1.9820 - mae: 1.1594 - mse: 1.9820 - val_loss: 3.5010 - val_mae: 1.6557 - val_mse: 3.5010\n",
      "Epoch 7/100\n",
      "96/96 [==============================] - 27s 285ms/step - loss: 1.7794 - mae: 1.0614 - mse: 1.7794 - val_loss: 9.2054 - val_mae: 1.9394 - val_mse: 9.2054\n",
      "Epoch 8/100\n",
      "96/96 [==============================] - 27s 284ms/step - loss: 1.7113 - mae: 1.0378 - mse: 1.7113 - val_loss: 19.0467 - val_mae: 2.8676 - val_mse: 19.0467\n",
      "Epoch 9/100\n",
      "96/96 [==============================] - 27s 286ms/step - loss: 1.3122 - mae: 0.8825 - mse: 1.3122 - val_loss: 63.3650 - val_mae: 5.5936 - val_mse: 63.3650\n",
      "Epoch 10/100\n",
      "96/96 [==============================] - 27s 285ms/step - loss: 1.1523 - mae: 0.8256 - mse: 1.1523 - val_loss: 4.0111 - val_mae: 1.7271 - val_mse: 4.0111\n",
      "Epoch 11/100\n",
      "96/96 [==============================] - 27s 284ms/step - loss: 1.2320 - mae: 0.8391 - mse: 1.2320 - val_loss: 83.3081 - val_mae: 5.5664 - val_mse: 83.3081\n",
      "finished training\n",
      "*------------------------------*\n",
      "\n",
      "starting evaluate\n",
      "*------------------------------*\n",
      "RMSE Score: 1.417512721822354\n",
      "MAE Score: 1.0919778648047205\n",
      "finished evaluate\n",
      "*------------------------------*\n",
      "\n"
     ]
    }
   ],
   "source": [
    "meta_features =\\\n",
    "    asset_df_A['asset_contract.name'].unique().tolist() + ['num_sales']\n",
    "\n",
    "path_list = np.vstack(\n",
    "    (asset_df_A['full_path'].values.reshape(-1, 1),\n",
    "     asset_df_B['full_path'].values.reshape(-1, 1))\n",
    ").reshape(-1)\n",
    "meta_data = np.vstack(\n",
    "    (asset_df_A[meta_features].values.reshape(-1, len(meta_features)),\n",
    "     asset_df_B[meta_features].values.reshape(-1, len(meta_features)))\n",
    ")\n",
    "target = np.vstack(\n",
    "    (asset_df_A['current_price'].values.reshape(-1, 1),\n",
    "     asset_df_B['current_price'].values.reshape(-1, 1))\n",
    ").reshape(-1)\n",
    "\n",
    "model_A = train(path_list, target, losses.mean_squared_error, meta_data,\n",
    "                task=\"A\")\n",
    "# save_model(model_A, \"../models/baselineA.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87444d2c-ae2a-4cc6-9776-6ab420b16ed4",
   "metadata": {},
   "source": [
    "### TaskB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "abcc6969-e9b1-4aed-bde1-22975d18fb10",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training\n",
      "*------------------------------*\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 9s 402ms/step - loss: 1.8283 - mae: 1.1222 - mse: 1.8283 - val_loss: 1.0194 - val_mae: 0.8556 - val_mse: 1.0194\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 1.7130 - mae: 1.0366 - mse: 1.7130 - val_loss: 0.6257 - val_mae: 0.5826 - val_mse: 0.6257\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 4s 292ms/step - loss: 1.6539 - mae: 1.0485 - mse: 1.6539 - val_loss: 0.5693 - val_mae: 0.5318 - val_mse: 0.5693\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 4s 287ms/step - loss: 1.4348 - mae: 0.9594 - mse: 1.4348 - val_loss: 0.5797 - val_mae: 0.5418 - val_mse: 0.5797\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 3s 285ms/step - loss: 1.3938 - mae: 0.9392 - mse: 1.3938 - val_loss: 0.5382 - val_mae: 0.5110 - val_mse: 0.5382\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 3s 283ms/step - loss: 1.9014 - mae: 1.0296 - mse: 1.9014 - val_loss: 0.5216 - val_mae: 0.4998 - val_mse: 0.5216\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 3s 284ms/step - loss: 1.4783 - mae: 0.9724 - mse: 1.4783 - val_loss: 0.4989 - val_mae: 0.4846 - val_mse: 0.4989\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 3s 286ms/step - loss: 1.5172 - mae: 0.9626 - mse: 1.5172 - val_loss: 0.4749 - val_mae: 0.4681 - val_mse: 0.4749\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 4s 290ms/step - loss: 1.4227 - mae: 0.9588 - mse: 1.4227 - val_loss: 0.4575 - val_mae: 0.4566 - val_mse: 0.4575\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 4s 286ms/step - loss: 1.3641 - mae: 0.9209 - mse: 1.3641 - val_loss: 0.4146 - val_mae: 0.4355 - val_mse: 0.4146\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 4s 288ms/step - loss: 1.2750 - mae: 0.8917 - mse: 1.2750 - val_loss: 0.3776 - val_mae: 0.4215 - val_mse: 0.3776\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 4s 285ms/step - loss: 1.2909 - mae: 0.8485 - mse: 1.2909 - val_loss: 0.3427 - val_mae: 0.4241 - val_mse: 0.3427\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 3s 283ms/step - loss: 1.0477 - mae: 0.8112 - mse: 1.0477 - val_loss: 0.3362 - val_mae: 0.4262 - val_mse: 0.3362\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 3s 282ms/step - loss: 1.0590 - mae: 0.7763 - mse: 1.0590 - val_loss: 0.3522 - val_mae: 0.4146 - val_mse: 0.3522\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 3s 283ms/step - loss: 1.1336 - mae: 0.8300 - mse: 1.1336 - val_loss: 0.3884 - val_mae: 0.4208 - val_mse: 0.3884\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 3s 283ms/step - loss: 1.3359 - mae: 0.8972 - mse: 1.3359 - val_loss: 0.3492 - val_mae: 0.4126 - val_mse: 0.3492\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 3s 284ms/step - loss: 1.1347 - mae: 0.8018 - mse: 1.1347 - val_loss: 0.3155 - val_mae: 0.4274 - val_mse: 0.3155\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 3s 284ms/step - loss: 1.0060 - mae: 0.7731 - mse: 1.0060 - val_loss: 0.3674 - val_mae: 0.4521 - val_mse: 0.3674\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 3s 284ms/step - loss: 0.8130 - mae: 0.7112 - mse: 0.8130 - val_loss: 0.2897 - val_mae: 0.4449 - val_mse: 0.2897\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 3s 283ms/step - loss: 0.8609 - mae: 0.7265 - mse: 0.8609 - val_loss: 0.3315 - val_mae: 0.4919 - val_mse: 0.3315\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 3s 285ms/step - loss: 0.8752 - mae: 0.7426 - mse: 0.8752 - val_loss: 0.3564 - val_mae: 0.5222 - val_mse: 0.3564\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 3s 283ms/step - loss: 0.8007 - mae: 0.6796 - mse: 0.8007 - val_loss: 0.4432 - val_mae: 0.6234 - val_mse: 0.4432\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 3s 282ms/step - loss: 0.7895 - mae: 0.7012 - mse: 0.7895 - val_loss: 0.5426 - val_mae: 0.6797 - val_mse: 0.5426\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 3s 286ms/step - loss: 0.7997 - mae: 0.7071 - mse: 0.7997 - val_loss: 0.5448 - val_mae: 0.6905 - val_mse: 0.5448\n",
      "finished training\n",
      "*------------------------------*\n",
      "\n",
      "starting evaluate\n",
      "*------------------------------*\n",
      "RMSE Score: 0.5382727628743195\n",
      "MAE Score: 0.6670337925061143\n",
      "finished evaluate\n",
      "*------------------------------*\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_list = asset_df_B['full_path'].values\n",
    "target = asset_df_B['current_price'].values\n",
    "\n",
    "model_B = train(path_list, target, losses.mean_squared_error)\n",
    "# save_model(model_B, \"../models/baselineB.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c4e02b-f661-43bc-9ec9-ef0f4d627d73",
   "metadata": {},
   "source": [
    "## Evaluate model  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2302c3d7-1051-4c23-8717-aba374fd0d01",
   "metadata": {},
   "source": [
    "### Task A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc482f19-9206-4817-b2ba-f2bff120e1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "RMSE Score: 1.4560774926892954\n",
      "MAE Score: 1.0512976401888874\n"
     ]
    }
   ],
   "source": [
    "file_name = \"../models/baselineA.pkl\"\n",
    "model = load_model(file_name)\n",
    "\n",
    "meta_features =\\\n",
    "    asset_df_A['asset_contract.name'].unique().tolist() + ['num_sales']\n",
    "\n",
    "path_list = np.vstack(\n",
    "    (asset_df_A['full_path'].values.reshape(-1, 1),\n",
    "     asset_df_B['full_path'].values.reshape(-1, 1))\n",
    ").reshape(-1)\n",
    "meta_data = np.vstack(\n",
    "    (asset_df_A[meta_features].values.reshape(-1, len(meta_features)),\n",
    "     asset_df_B[meta_features].values.reshape(-1, len(meta_features)))\n",
    ")\n",
    "target = np.vstack(\n",
    "    (asset_df_A['current_price'].values.reshape(-1, 1),\n",
    "     asset_df_B['current_price'].values.reshape(-1, 1))\n",
    ").reshape(-1)\n",
    "\n",
    "train_path, val_path, train_meta, val_meta, train_y, val_y =\\\n",
    "    train_test_split(path_list, meta_data, target, test_size=0.1, random_state=6174)\n",
    "\n",
    "val_gen = FullPathDataLoader(path_list=val_path,\n",
    "                             meta_data=val_meta, target=val_y,\n",
    "                             batch_size=1, shuffle=False, is_train=False)\n",
    "\n",
    "model.evaluate(val_gen, val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c61d60-b0ad-4ffa-8568-debe83ba19eb",
   "metadata": {},
   "source": [
    "### Task B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68e89386-5031-48f4-8ded-7112b64eb462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "RMSE Score: 0.6399370806244283\n",
      "MAE Score: 0.6960668109029233\n"
     ]
    }
   ],
   "source": [
    "file_name = \"../models/baselineB.pkl\"\n",
    "model = load_model(file_name)\n",
    "\n",
    "path_list = asset_df_B['full_path'].values\n",
    "meta_data = asset_df_B[meta_features].values\n",
    "target = asset_df_B['current_price'].values\n",
    "\n",
    "train_path, val_path, train_meta, val_meta, train_y, val_y =\\\n",
    "    train_test_split(path_list, meta_data, target, test_size=0.1, random_state=6174)\n",
    "\n",
    "val_gen = FullPathDataLoader(path_list=val_path,\n",
    "                             meta_data=val_meta, target=val_y,\n",
    "                             batch_size=1, shuffle=False, is_train=False)\n",
    "\n",
    "model.evaluate(val_gen, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87627221-a503-49cc-8210-054078815218",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
